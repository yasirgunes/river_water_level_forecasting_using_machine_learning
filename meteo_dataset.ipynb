{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
      "Missing proportion per column:\n",
      " pres    0.006971\n",
      "temp    0.000531\n",
      "rhum    0.001019\n",
      "wspd    0.001876\n",
      "dtype: float64\n",
      "Final data snapshot:\n",
      "                       pres  temp  rhum  wspd\n",
      "time                                         \n",
      "1995-10-01 00:00:00  1022.8  16.1  90.0   7.6\n",
      "1995-10-01 01:00:00  1023.1  15.0  93.0   7.6\n",
      "1995-10-01 02:00:00  1023.5  15.6  93.0  11.2\n",
      "1995-10-01 03:00:00  1023.1  15.6  90.0  11.2\n",
      "1995-10-01 04:00:00  1022.7  15.6  90.0   7.6\n",
      "\n",
      "Hourly data shape: (260065, 4)\n",
      "Daily data shape: (10837, 4)\n",
      "\n",
      "Daily data sample:\n",
      "               pres   temp   rhum   wspd\n",
      "time                                    \n",
      "1995-10-01  1021.18  17.63  82.83   8.01\n",
      "1995-10-02  1018.78  17.85  83.46   6.87\n",
      "1995-10-03  1015.09  17.94  93.92    8.4\n",
      "1995-10-04   1011.3  16.96  98.79   5.57\n",
      "1995-10-05  1002.01  20.36  91.67  25.63\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from meteostat import Point, Hourly\n",
    "\n",
    "# Parameters\n",
    "start = datetime(1995, 10, 1)\n",
    "end   = datetime(2025, 6, 1)\n",
    "location = Point(35.4333, -82.0333, 660)\n",
    "\n",
    "# Fetch hourly data\n",
    "df = Hourly(location, start, end).fetch()\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "# Create model inputs\n",
    "df_clean = df[['pres', 'temp', 'rhum', 'wspd']].copy()\n",
    "\n",
    "# Verify no missing values\n",
    "print(\"Missing proportion per column:\\n\", df_clean.isna().mean())\n",
    "\n",
    "# Interpolate time gaps (there should be none, but good practice)\n",
    "df_clean = df_clean.interpolate(method='time')\n",
    "\n",
    "print(\"Final data snapshot:\")\n",
    "print(df_clean.head())\n",
    "\n",
    "# Convert hourly data to daily aggregations\n",
    "df_daily = df_clean.resample('D').agg({\n",
    "    'pres': 'mean',      # Average daily pressure\n",
    "    'temp': 'mean',      # Average daily temperature\n",
    "    'rhum': 'mean',      # Average daily relative humidity\n",
    "    'wspd': 'mean'       # Average daily wind speed\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nHourly data shape: {df_clean.shape}\")\n",
    "print(f\"Daily data shape: {df_daily.shape}\")\n",
    "print(\"\\nDaily data sample:\")\n",
    "print(df_daily.head())\n",
    "\n",
    "# save the dataframe to a csv file named \"weather_dataset.csv\" with datetime as index\n",
    "df_daily.to_csv(\"weather_dataset.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Weather dataset shape: (10837, 4)\n",
      "Weather data sample:\n",
      "               pres   temp   rhum   wspd\n",
      "time                                    \n",
      "1995-10-01  1021.18  17.63  82.83   8.01\n",
      "1995-10-02  1018.78  17.85  83.46   6.87\n",
      "1995-10-03  1015.09  17.94  93.92   8.40\n",
      "1995-10-04  1011.30  16.96  98.79   5.57\n",
      "1995-10-05  1002.01  20.36  91.67  25.63\n",
      "\n",
      "Water level dataset shape: (10837, 2)\n",
      "Water level data sample:\n",
      "                   datetime  stage_m\n",
      "0 1995-10-01 00:00:00+00:00     1.96\n",
      "1 1995-10-02 00:00:00+00:00     1.93\n",
      "2 1995-10-03 00:00:00+00:00     1.91\n",
      "3 1995-10-04 00:00:00+00:00     3.79\n",
      "4 1995-10-05 00:00:00+00:00     5.41\n",
      "\n",
      "After processing:\n",
      "Weather dates range: 1995-10-01 to 2025-06-01\n",
      "Water level dates range: 1995-10-01 to 2025-06-01\n",
      "\n",
      "Combined dataset shape: (10837, 6)\n",
      "Combined data sample:\n",
      "        index  stage_m     pres   temp   rhum   wspd\n",
      "0  1995-10-01     1.96  1021.18  17.63  82.83   8.01\n",
      "1  1995-10-02     1.93  1018.78  17.85  83.46   6.87\n",
      "2  1995-10-03     1.91  1015.09  17.94  93.92   8.40\n",
      "3  1995-10-04     3.79  1011.30  16.96  98.79   5.57\n",
      "4  1995-10-05     5.41  1002.01  20.36  91.67  25.63\n",
      "\n",
      "Missing values in combined dataset:\n",
      "index       0\n",
      "stage_m    49\n",
      "pres        0\n",
      "temp        0\n",
      "rhum        0\n",
      "wspd        0\n",
      "dtype: int64\n",
      "\n",
      "Combined dataset saved as 'combined_dataset.csv'\n",
      "Final dataset has 10837 rows and 6 columns\n",
      "Columns: ['index', 'stage_m', 'pres', 'temp', 'rhum', 'wspd']\n"
     ]
    }
   ],
   "source": [
    "# Load both datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load weather data\n",
    "weather_df = pd.read_csv(\"weather_dataset.csv\", index_col=0, parse_dates=True)\n",
    "print(f\"Weather dataset shape: {weather_df.shape}\")\n",
    "print(\"Weather data sample:\")\n",
    "print(weather_df.head())\n",
    "\n",
    "# Load water level data  \n",
    "water_df = pd.read_csv(\"dataset.csv\", parse_dates=['datetime'])\n",
    "print(f\"\\nWater level dataset shape: {water_df.shape}\")\n",
    "print(\"Water level data sample:\")\n",
    "print(water_df.head())\n",
    "\n",
    "# Convert datetime to date for alignment (remove time component)\n",
    "water_df['date'] = water_df['datetime'].dt.date\n",
    "weather_df.index = pd.to_datetime(weather_df.index).date\n",
    "\n",
    "# Set date as index for water level data\n",
    "water_df = water_df.set_index('date').drop('datetime', axis=1)\n",
    "\n",
    "print(f\"\\nAfter processing:\")\n",
    "print(f\"Weather dates range: {weather_df.index.min()} to {weather_df.index.max()}\")\n",
    "print(f\"Water level dates range: {water_df.index.min()} to {water_df.index.max()}\")\n",
    "\n",
    "# Combine datasets using inner join (only dates that exist in both)\n",
    "combined_df = weather_df.join(water_df, how='inner')\n",
    "\n",
    "# Reorder columns to put datetime first and stage_m second\n",
    "combined_df = combined_df.reset_index()\n",
    "combined_df = combined_df[['index', 'stage_m'] + [col for col in combined_df.columns if col not in ['index', 'stage_m']]]\n",
    "\n",
    "print(f\"\\nCombined dataset shape: {combined_df.shape}\")\n",
    "print(\"Combined data sample:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in combined dataset:\")\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# Save the combined dataset\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n",
    "print(f\"\\nCombined dataset saved as 'combined_dataset.csv'\")\n",
    "print(f\"Final dataset has {len(combined_df)} rows and {len(combined_df.columns)} columns\")\n",
    "print(f\"Columns: {combined_df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
